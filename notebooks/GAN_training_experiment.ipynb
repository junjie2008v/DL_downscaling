{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN_descriminator_experiments\n",
    "\n",
    "* check if the descriminator is generalizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# graph tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# custom tools\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/utils/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/DL_downscaling/utils/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/DL_downscaling/')\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "import train_utils as tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_utils' from '/glade/u/home/ksha/WORKSPACE/DL_downscaling/utils/model_utils.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea = 'jja' # testing in the JJA season\n",
    "N_input = 3 # LR T2, HR elev, LR elev\n",
    "VAR = 'TMEAN'\n",
    "\n",
    "N = [56, 112, 224, 448] # number of channels per downsampling level\n",
    "l = [1e-4, 2e-4] # G lr; D lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator**, initialized with pre-trained UNET weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import model: UNET3_TMEAN_jja_tune\n",
      "Compiling G\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "model_name = 'UNET3_{}_{}_tune'.format(VAR, sea)\n",
    "model_path = temp_dir+model_name+'.hdf'\n",
    "print('Import model: {}'.format(model_name))\n",
    "backbone = keras.models.load_model(model_path)\n",
    "W = backbone.get_weights()\n",
    "\n",
    "# generator\n",
    "G = mu.UNET(N, (None, None, N_input))\n",
    "# optimizer\n",
    "opt_G = keras.optimizers.Adam(lr=l[0])\n",
    "\n",
    "print('Compiling G')\n",
    "G.compile(loss=keras.losses.mean_absolute_error, optimizer=opt_G)\n",
    "G.set_weights(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriminator**, pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import model: GAN_D_TMEAN_jja\n",
      "Compiling D\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "model_name = 'GAN_D_{}_{}'.format(VAR, sea)\n",
    "model_path = temp_dir+model_name+'.hdf'\n",
    "\n",
    "print('Import model: {}'.format(model_name))\n",
    "backbone = keras.models.load_model(model_path)\n",
    "W = backbone.get_weights()\n",
    "\n",
    "input_size = (None, None, N_input+1)\n",
    "D = mu.vgg_descriminator(N, input_size)\n",
    "\n",
    "opt_D = keras.optimizers.Adam(lr=l[1])\n",
    "print('Compiling D')\n",
    "D.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt_D)\n",
    "D.set_weights(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling GAN\n"
     ]
    }
   ],
   "source": [
    "GAN_IN = keras.layers.Input((None, None, N_input))\n",
    "G_OUT = G(GAN_IN)\n",
    "D_IN = keras.layers.Concatenate()([G_OUT, GAN_IN])\n",
    "D_OUT = D(D_IN)\n",
    "GAN = keras.models.Model(GAN_IN, [G_OUT, D_OUT])\n",
    "\n",
    "print('Compiling GAN')\n",
    "# content_loss + 1e-3 * adversarial_loss\n",
    "GAN.compile(loss=[keras.losses.mean_absolute_error, keras.losses.categorical_crossentropy], \n",
    "            loss_weights=[1.0, 1e-3],\n",
    "            optimizer=opt_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train domain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = BATCH_dir\n",
    "trainfiles = glob(file_path+'{}_BATCH_*_TORI*_{}*.npy'.format(VAR, sea)) # e.g., TMAX_BATCH_128_VORIAUG_mam30.npy\n",
    "validfiles = glob(file_path+'{}_BATCH_*_VORI*_{}*.npy'.format(VAR, sea))\n",
    "# shuffle filenames\n",
    "shuffle(trainfiles)\n",
    "shuffle(validfiles)\n",
    "#\n",
    "L_train = len(trainfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 200\n",
    "\n",
    "y_bad = np.zeros(batch_size)\n",
    "y_good = np.ones(batch_size)\n",
    "dummy_good = keras.utils.to_categorical(y_good)\n",
    "dummy_mix = keras.utils.to_categorical(np.concatenate((y_bad, y_good), axis=0))\n",
    "\n",
    "input_flag = [False, True, False, False, True, True] # LR T2, HR elev, LR elev\n",
    "output_flag = [True, False, False, False, False, False] # HR T2\n",
    "inout_flag = [True, True, False, False, True, True]\n",
    "labels = ['batch', 'batch'] # input and output labels\n",
    "\n",
    "gen_valid = tu.grid_grid_gen(validfiles, labels, input_flag, output_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "328/328 [==============================] - 80s 244ms/step - loss: 0.1218\n",
      "Initial validation loss: 0.121833568734185\n",
      "\t0 step loss = [0.09364493, 0.090682946, 2.9619842]\n",
      "\t100 step loss = [0.07590298, 0.07583536, 0.067624494]\n",
      "\t200 step loss = [0.06917895, 0.069178484, 0.00046310015]\n",
      "\t300 step loss = [0.08624333, 0.0862173, 0.02603416]\n",
      "\t400 step loss = [0.09107561, 0.091063626, 0.01197927]\n",
      "\t500 step loss = [0.06555204, 0.06555203, 1.0757482e-05]\n",
      "\t600 step loss = [0.08892163, 0.08891756, 0.0040644626]\n",
      "\t700 step loss = [0.09121706, 0.091216095, 0.00096733903]\n",
      "\t800 step loss = [0.06757206, 0.06757205, 8.73821e-06]\n",
      "\t900 step loss = [0.072589494, 0.072589375, 0.00011726563]\n",
      "328/328 [==============================] - 99s 303ms/step - loss: 0.1093\n",
      "Validation loss improved from 0.121833568734185 to 0.10925981004881423\n",
      "--- 2020.7207915782928 seconds ---\n",
      "epoch = 1\n",
      "\t0 step loss = [0.0881509, 0.08812803, 0.022873025]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-549a0a91b36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mgan_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_good\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mgan_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Backup training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mD_LOSS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mL_train\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m     \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_get_training_value\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trainable_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mlogical_and\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   5858\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   5859\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5860\u001b[0;31m         \"LogicalAnd\", name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   5861\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5862\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#record = np.inf\n",
    "min_del = 0.00001\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "# loss backup\n",
    "GAN_LOSS = np.zeros([int(epochs*L_train), 3])*np.nan\n",
    "D_LOSS = np.zeros([int(epochs*L_train)])*np.nan\n",
    "V_LOSS = np.zeros([epochs])\n",
    "                  \n",
    "for i in range(epochs):\n",
    "    print('epoch = {}'.format(i))\n",
    "    if i == 0:\n",
    "        record = G.evaluate_generator(gen_valid, verbose=1)\n",
    "        print('Initial validation loss: {}'.format(record))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    # learning rate schedule\n",
    "    \n",
    "    # shuffling at epoch begin\n",
    "    shuffle(trainfiles)\n",
    "    # loop over batches\n",
    "    for j, name in enumerate(trainfiles):\n",
    "\n",
    "        # import batch data\n",
    "        temp_batch = np.load(name, allow_pickle=True)[()]\n",
    "        X = temp_batch['batch'][...]\n",
    "\n",
    "        # get G_output\n",
    "        D.trainable = True\n",
    "        g_in = X[..., input_flag]\n",
    "        g_out = G.predict([g_in]) # <-- np.array\n",
    "\n",
    "        # test D with G_output\n",
    "        d_in_fake = np.concatenate((g_out, g_in), axis=-1) # channel last\n",
    "        d_in_true = X[..., inout_flag]\n",
    "        d_in = np.concatenate((d_in_fake, d_in_true), axis=0) # batch size doubled\n",
    "        d_target = dummy_mix\n",
    "        d_shuffle_ind = du.shuffle_ind(2*batch_size)\n",
    "        d_loss = D.train_on_batch(d_in[d_shuffle_ind, ...], d_target[d_shuffle_ind, ...])\n",
    "\n",
    "        # G training / transferring\n",
    "        D.trainable = False\n",
    "        gan_in = X[..., input_flag]\n",
    "        gan_target = [X[..., output_flag], dummy_good]\n",
    "\n",
    "        gan_loss = GAN.train_on_batch(gan_in, gan_target)\n",
    "        # Backup training loss\n",
    "        D_LOSS[i*L_train+j] = d_loss\n",
    "        GAN_LOSS[i*L_train+j, :] = gan_loss\n",
    "        #\n",
    "        if j%100 == 0:\n",
    "            print('\\t{} step loss = {}'.format(j, gan_loss))\n",
    "    # on epoch-end\n",
    "    record_temp = G.evaluate_generator(gen_valid, verbose=1)\n",
    "                  \n",
    "    # Backup validation loss\n",
    "    V_LOSS[i] = record_temp\n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        # save\n",
    "        #print('save to: ')\n",
    "        #G.save\n",
    "        #D.save\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            break;\n",
    "        else:\n",
    "            continue;\n",
    "            \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # mannual callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.evaluate_generator(gen_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b7aefd862d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(V_LOSS[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4965, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAN_LOSS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
