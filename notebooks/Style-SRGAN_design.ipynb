{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import sys\n",
    "from glob import glob\n",
    "# data tools\n",
    "import time\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# custom tools\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/utils/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/DL_downscaling/utils/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/WORKSPACE/DL_downscaling/')\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "import train_utils as tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_utils' from '/glade/u/home/ksha/WORKSPACE/DL_downscaling/utils/model_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "             axis=-1,\n",
    "             momentum=0.99,\n",
    "             epsilon=1e-3,\n",
    "             center=True,\n",
    "             scale=True,\n",
    "             **kwargs):\n",
    "        super(AdaIN, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "    \n",
    "    \n",
    "    def build(self, input_shape):\n",
    "    \n",
    "        dim = input_shape[0][self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape[0]) + '.')\n",
    "    \n",
    "        super(AdaIN, self).build(input_shape) \n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = K.int_shape(inputs[0])\n",
    "        reduction_axes = list(range(0, len(input_shape)))\n",
    "        \n",
    "        beta = inputs[1]\n",
    "        gamma = inputs[2]\n",
    "\n",
    "        if self.axis is not None:\n",
    "            del reduction_axes[self.axis]\n",
    "\n",
    "        del reduction_axes[0]\n",
    "        mean = K.mean(inputs[0], reduction_axes, keepdims=True)\n",
    "        stddev = K.std(inputs[0], reduction_axes, keepdims=True) + self.epsilon\n",
    "        normed = (inputs[0] - mean) / stddev\n",
    "\n",
    "        return normed * gamma + beta\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis,\n",
    "            'momentum': self.momentum,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale\n",
    "        }\n",
    "        base_config = super(AdaIN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "    \n",
    "        return input_shape[0]\n",
    "\n",
    "def stride_conv(X, channel, pool_size, activation='relu'):\n",
    "    X = keras.layers.Conv2D(channel, pool_size, strides=(pool_size, pool_size), padding='valid', \n",
    "                            use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
    "    if activation == 'relu':\n",
    "        X = keras.layers.ReLU()(X)\n",
    "    elif activation == 'leaky':\n",
    "        X = keras.layers.LeakyReLU(alpha=0.3)(X)\n",
    "    return X\n",
    "\n",
    "def DENSE_stack(X, units):\n",
    "    L = len(units)\n",
    "    for i in range(L):\n",
    "        X = keras.layers.Dense(units[i], use_bias=False, kernel_initializer='he_normal')(X)\n",
    "        X = keras.layers.BatchNormalization()(X)\n",
    "        X = keras.layers.ReLU()(X)\n",
    "    return X\n",
    "\n",
    "def CONV_stack(X, channel, kernel_size, stack_num, activation='relu'):\n",
    "    '''\n",
    "    Stacked convolution-BN-ReLU blocks\n",
    "    '''\n",
    "    for i in range(stack_num):\n",
    "        X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "        X = keras.layers.BatchNormalization(axis=3)(X)\n",
    "        if activation == 'relu':\n",
    "            X = keras.layers.ReLU()(X)\n",
    "        elif activation == 'leaky':\n",
    "            X = keras.layers.LeakyReLU(alpha=0.3)(X)\n",
    "    return X\n",
    "\n",
    "# UNet\n",
    "def UNET_left(X, channel, kernel_size=3, pool_size=2, pool=True, activation='relu'):\n",
    "    if pool:\n",
    "        X = keras.layers.MaxPooling2D(pool_size=(pool_size, pool_size))(X)\n",
    "    else:\n",
    "        X = stride_conv(X, channel, pool_size, activation=activation)\n",
    "    X = CONV_stack(X, channel, kernel_size, stack_num=1, activation=activation)\n",
    "    return X\n",
    "\n",
    "def UNET_right(X, X_left, channel, kernel_size=3, pool_size=2, activation='relu'):\n",
    "    X = keras.layers.Conv2DTranspose(channel, kernel_size, strides=(pool_size, pool_size), padding='same')(X)\n",
    "    X = CONV_stack(X, channel, kernel_size, stack_num=1, activation=activation) \n",
    "    H = keras.layers.concatenate([X_left, X], axis=3)\n",
    "    H = CONV_stack(H, channel, kernel_size, stack_num=1, activation=activation)\n",
    "    return H\n",
    "\n",
    "def UNET_in_style(X, STY, channel, kernel_size=3, pool_size=2, pool=True, activation='relu'):\n",
    "    # Conv layer\n",
    "    X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    # additive noise (not applied)\n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    X = AdaIN()([X, b, g])\n",
    "    # ----------------- #\n",
    "    X = keras.layers.ReLU()(X)\n",
    "    \n",
    "    # Conv layer x2\n",
    "    X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    # additive noise (not applied)\n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    X = AdaIN()([X, b, g])\n",
    "    # ----------------- #\n",
    "    X = keras.layers.ReLU()(X)\n",
    "    return X\n",
    "\n",
    "def UNET_out_style(X, STY, channel=2, kernel_size=3, pool_size=2, pool=True, activation='relu'):\n",
    "    # Conv layer\n",
    "    X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    # additive noise (not applied)\n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    X = AdaIN()([X, b, g])\n",
    "    # ----------------- #\n",
    "    X = keras.layers.ReLU()(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def UNET_left_style(X, STY, channel, kernel_size=3, pool_size=2, pool=True, activation='relu'):\n",
    "    # downsampling layer\n",
    "    if pool:\n",
    "        X = keras.layers.MaxPooling2D(pool_size=(pool_size, pool_size))(X)\n",
    "    else:\n",
    "        X = stride_conv(X, channel, pool_size, activation=activation)\n",
    "    # Conv layer\n",
    "    X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    \n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    X = AdaIN()([X, b, g])\n",
    "    # ----------------- #\n",
    "    # additive noise (not applied)\n",
    "    X = keras.layers.ReLU()(X)\n",
    "    return X\n",
    "\n",
    "def UNET_right_style(X, X_left, STY, channel, kernel_size=3, pool_size=2, activation='relu'):\n",
    "    \n",
    "    # up-sampling\n",
    "    X = keras.layers.Conv2DTranspose(channel, kernel_size, strides=(pool_size, pool_size), padding='same')(X)\n",
    "    \n",
    "    # conv\n",
    "    X = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(X)\n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    X = AdaIN()([X, b, g])\n",
    "    # ----------------- #\n",
    "    X = keras.layers.ReLU()(X)\n",
    "    \n",
    "    H = keras.layers.concatenate([X_left, X], axis=3)\n",
    "    # conv\n",
    "    H = keras.layers.Conv2D(channel, kernel_size, padding='same', use_bias=False, kernel_initializer='he_normal')(H)\n",
    "    # ----- AdaIN ----- #\n",
    "    # affine transform\n",
    "    b = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    b = keras.layers.Reshape([1, 1, channel])(b)\n",
    "    g = keras.layers.Dense(channel, activation=keras.activations.linear)(STY)\n",
    "    g = keras.layers.Reshape([1, 1, channel])(g)\n",
    "    # AdaIN\n",
    "    H = AdaIN()([H, b, g])\n",
    "    # ----------------- #\n",
    "    H = keras.layers.ReLU()(H)\n",
    "    return H    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-SRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_input = 3\n",
    "input_size = (None, None, N_input)\n",
    "input_stack_num = 2\n",
    "pool = False\n",
    "activation = 'relu'\n",
    "N = [48, 96, 192, 384]\n",
    "l = [5e-5, 5e-5] # G lr; D lr\n",
    "lmd = 1e-3\n",
    "epochs = 150\n",
    "# early stopping settings\n",
    "min_del = 0\n",
    "max_tol = 10 # early stopping with patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea = 'jja' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = N[-1]\n",
    "mapping_size = N[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN1 = keras.layers.Input(shape=[latent_size])\n",
    "# # layer 1\n",
    "# STY = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(IN1)\n",
    "# STY = keras.layers.ReLU()(STY)\n",
    "# # layer 2\n",
    "# STY = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY)\n",
    "# STY = keras.layers.ReLU()(STY)\n",
    "# # layer 3\n",
    "# STY = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY)\n",
    "# STY = keras.layers.ReLU()(STY)\n",
    "\n",
    "# IN2 = keras.layers.Input(input_size)\n",
    "# # left blocks\n",
    "# X_en1 = UNET_in_style(IN2, STY, N[0], activation=activation)\n",
    "# X_en2 = UNET_left_style(X_en1, STY, N[1], pool=pool, activation=activation)\n",
    "# X_en3 = UNET_left_style(X_en2, STY, N[2], pool=pool, activation=activation)\n",
    "# # bottom\n",
    "# X4 = UNET_left_style(X_en3, STY, N[3], pool=pool, activation=activation)\n",
    "# # right blocks\n",
    "# X_de3 = UNET_right(X4, X_en3, N[2], activation=activation)\n",
    "# X_de2 = UNET_right(X_de3, X_en2, N[1], activation=activation)\n",
    "# X_de1 = UNET_right(X_de2, X_en1, N[0], activation=activation)\n",
    "# # output\n",
    "# OUT = CONV_stack(X_de1, 2, kernel_size=3, stack_num=1, activation=activation)\n",
    "# OUT = keras.layers.Conv2D(1, 1, activation=keras.activations.linear, padding='same')(OUT)\n",
    "# G_style = keras.models.Model(inputs=[IN1, IN2], outputs=[OUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN1 = keras.layers.Input(shape=[latent_size])\n",
    "# # layer 1\n",
    "# STY1 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(IN1)\n",
    "# STY1 = keras.layers.ReLU()(STY1)\n",
    "# # layer 2\n",
    "# STY1 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY1)\n",
    "# STY1 = keras.layers.ReLU()(STY1)\n",
    "# # layer 3\n",
    "# STY1 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY1)\n",
    "# STY1 = keras.layers.ReLU()(STY1)\n",
    "\n",
    "\n",
    "# IN2 = keras.layers.Input(shape=[latent_size])\n",
    "# # layer 1\n",
    "# STY2 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(IN2)\n",
    "# STY2 = keras.layers.ReLU()(STY2)\n",
    "# # layer 2\n",
    "# STY2 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY2)\n",
    "# STY2 = keras.layers.ReLU()(STY2)\n",
    "# # layer 3\n",
    "# STY2 = keras.layers.Dense(mapping_size, kernel_initializer='he_normal')(STY2)\n",
    "# STY2 = keras.layers.ReLU()(STY2)\n",
    "\n",
    "\n",
    "# IN3 = keras.layers.Input(input_size)\n",
    "# # left blocks\n",
    "# X_en1 = UNET_in_style(IN3, STY1, N[0], activation=activation)\n",
    "# X_en2 = UNET_left_style(X_en1, STY1, N[1], pool=pool, activation=activation)\n",
    "# X_en3 = UNET_left_style(X_en2, STY1, N[2], pool=pool, activation=activation)\n",
    "# # bottom\n",
    "# X4 = UNET_left_style(X_en3, STY2, N[3], pool=pool, activation=activation)\n",
    "# # right blocks\n",
    "# X_de3 = UNET_right_style(X4, X_en3, STY2, N[2], activation=activation)\n",
    "# X_de2 = UNET_right_style(X_de3, X_en2, STY2, N[1], activation=activation)\n",
    "# X_de1 = UNET_right_style(X_de2, X_en1, STY2, N[0], activation=activation)\n",
    "# # output\n",
    "# OUT = UNET_out_style(X_de1, STY2, activation=activation)\n",
    "# OUT = keras.layers.Conv2D(1, 1, activation=keras.activations.linear, padding='same')(OUT)\n",
    "# G_style = keras.models.Model(inputs=[IN1, IN2, IN3], outputs=[OUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(G_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling G\n"
     ]
    }
   ],
   "source": [
    "G_style = mu.UNET_STYLE(N, input_size, 4, latent_size, mapping_size, pool=pool, activation=activation, noise=[0.2, 0.1])\n",
    "opt_G = keras.optimizers.Adam(lr=0) # <--- compile G for validation only\n",
    "print('Compiling G')\n",
    "G_style.compile(loss=keras.losses.mean_squared_error, optimizer=opt_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "unet_in (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack0_conv (Conv2D) (None, None, None, 4 1296        unet_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack0_bn (BatchNorm (None, None, None, 4 192         unet_left0_stack0_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack0_relu (ReLU)   (None, None, None, 4 0           unet_left0_stack0_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack1_conv (Conv2D) (None, None, None, 4 20736       unet_left0_stack0_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack1_bn (BatchNorm (None, None, None, 4 192         unet_left0_stack1_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "unet_left0_stack1_relu (ReLU)   (None, None, None, 4 0           unet_left0_stack1_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stride_conv (Conv2D) (None, None, None, 9 18432       unet_left0_stack1_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stride_conv_bn (Batc (None, None, None, 9 384         unet_left1_stride_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stride_conv_relu (Re (None, None, None, 9 0           unet_left1_stride_conv_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stack0_conv (Conv2D) (None, None, None, 9 82944       unet_left1_stride_conv_relu[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mapping_in (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stack0_bn (BatchNorm (None, None, None, 9 384         unet_left1_stack0_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden0 (Dense)         (None, 384)          147840      mapping_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_left1_stack0_relu (ReLU)   (None, None, None, 9 0           unet_left1_stack0_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden_relu0 (ReLU)     (None, 384)          0           mapping_hidden0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stride_conv (Conv2D) (None, None, None, 1 73728       unet_left1_stack0_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden1 (Dense)         (None, 384)          147840      mapping_hidden_relu0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stride_conv_bn (Batc (None, None, None, 1 768         unet_left2_stride_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden_relu1 (ReLU)     (None, 384)          0           mapping_hidden1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stride_conv_relu (Re (None, None, None, 1 0           unet_left2_stride_conv_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden2 (Dense)         (None, 384)          147840      mapping_hidden_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stack0_conv (Conv2D) (None, None, None, 1 331776      unet_left2_stride_conv_relu[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden_relu2 (ReLU)     (None, 384)          0           mapping_hidden2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stack0_bn (BatchNorm (None, None, None, 1 768         unet_left2_stack0_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden3 (Dense)         (None, 384)          147840      mapping_hidden_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_left2_stack0_relu (ReLU)   (None, None, None, 1 0           unet_left2_stack0_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden_relu3 (ReLU)     (None, 384)          0           mapping_hidden3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_stride_conv (Conv2D (None, None, None, 3 294912      unet_left2_stack0_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden4 (Dense)         (None, 384)          147840      mapping_hidden_relu3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_stride_conv_bn (Bat (None, None, None, 3 1536        unet_bottom_stride_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mapping_hidden_relu4 (ReLU)     (None, 384)          0           mapping_hidden4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_stride_conv_relu (R (None, None, None, 3 0           unet_bottom_stride_conv_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_AdaIN_b (Dense)     (None, 384)          147840      mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_AdaIN_g (Dense)     (None, 384)          147840      mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_conv (Conv2D)       (None, None, None, 3 1327104     unet_bottom_stride_conv_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 384)    0           unet_bottom_AdaIN_b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 384)    0           unet_bottom_AdaIN_g[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_8 (AdaIN)                (None, None, None, 3 0           unet_bottom_conv[0][0]           \n",
      "                                                                 reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_gaussian_drop (Gaus (None, None, None, 3 0           ada_in_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "unet_bottom_relu (ReLU)         (None, None, None, 3 0           unet_bottom_gaussian_drop[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_trans_conv (Conv2DT (None, None, None, 1 663744      unet_bottom_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_AdaIN0_b (Dense)    (None, 192)          73920       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_AdaIN0_g (Dense)    (None, 192)          73920       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_conv0 (Conv2D)      (None, None, None, 1 331776      unet_right2_trans_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 1, 192)    0           unet_right2_AdaIN0_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 1, 192)    0           unet_right2_AdaIN0_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_9 (AdaIN)                (None, None, None, 1 0           unet_right2_conv0[0][0]          \n",
      "                                                                 reshape_18[0][0]                 \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_gaussian_drop0 (Gau (None, None, None, 1 0           ada_in_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_relu0 (ReLU)        (None, None, None, 1 0           unet_right2_gaussian_drop0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           unet_left2_stack0_relu[0][0]     \n",
      "                                                                 unet_right2_relu0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_AdaIN1_b (Dense)    (None, 192)          73920       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_AdaIN1_g (Dense)    (None, 192)          73920       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_conv1 (Conv2D)      (None, None, None, 1 663552      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 1, 1, 192)    0           unet_right2_AdaIN1_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 1, 192)    0           unet_right2_AdaIN1_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_10 (AdaIN)               (None, None, None, 1 0           unet_right2_conv1[0][0]          \n",
      "                                                                 reshape_20[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_gaussian_drop1 (Gau (None, None, None, 1 0           ada_in_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right2_relu1 (ReLU)        (None, None, None, 1 0           unet_right2_gaussian_drop1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_trans_conv (Conv2DT (None, None, None, 9 165984      unet_right2_relu1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_AdaIN0_b (Dense)    (None, 96)           36960       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_AdaIN0_g (Dense)    (None, 96)           36960       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_conv0 (Conv2D)      (None, None, None, 9 82944       unet_right1_trans_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 1, 1, 96)     0           unet_right1_AdaIN0_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 1, 1, 96)     0           unet_right1_AdaIN0_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_11 (AdaIN)               (None, None, None, 9 0           unet_right1_conv0[0][0]          \n",
      "                                                                 reshape_22[0][0]                 \n",
      "                                                                 reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_gaussian_drop0 (Gau (None, None, None, 9 0           ada_in_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_relu0 (ReLU)        (None, None, None, 9 0           unet_right1_gaussian_drop0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 1 0           unet_left1_stack0_relu[0][0]     \n",
      "                                                                 unet_right1_relu0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_AdaIN1_b (Dense)    (None, 96)           36960       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_AdaIN1_g (Dense)    (None, 96)           36960       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_conv1 (Conv2D)      (None, None, None, 9 165888      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 1, 1, 96)     0           unet_right1_AdaIN1_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 1, 1, 96)     0           unet_right1_AdaIN1_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_12 (AdaIN)               (None, None, None, 9 0           unet_right1_conv1[0][0]          \n",
      "                                                                 reshape_24[0][0]                 \n",
      "                                                                 reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_gaussian_drop1 (Gau (None, None, None, 9 0           ada_in_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right1_relu1 (ReLU)        (None, None, None, 9 0           unet_right1_gaussian_drop1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_trans_conv (Conv2DT (None, None, None, 4 41520       unet_right1_relu1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_AdaIN0_b (Dense)    (None, 48)           18480       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_AdaIN0_g (Dense)    (None, 48)           18480       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_conv0 (Conv2D)      (None, None, None, 4 20736       unet_right0_trans_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 1, 1, 48)     0           unet_right0_AdaIN0_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 1, 1, 48)     0           unet_right0_AdaIN0_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_13 (AdaIN)               (None, None, None, 4 0           unet_right0_conv0[0][0]          \n",
      "                                                                 reshape_26[0][0]                 \n",
      "                                                                 reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_gaussian_drop0 (Gau (None, None, None, 4 0           ada_in_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_relu0 (ReLU)        (None, None, None, 4 0           unet_right0_gaussian_drop0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 9 0           unet_left0_stack1_relu[0][0]     \n",
      "                                                                 unet_right0_relu0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_AdaIN1_b (Dense)    (None, 48)           18480       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_AdaIN1_g (Dense)    (None, 48)           18480       mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_conv1 (Conv2D)      (None, None, None, 4 41472       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 1, 1, 48)     0           unet_right0_AdaIN1_b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 1, 1, 48)     0           unet_right0_AdaIN1_g[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_14 (AdaIN)               (None, None, None, 4 0           unet_right0_conv1[0][0]          \n",
      "                                                                 reshape_28[0][0]                 \n",
      "                                                                 reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_gaussian_drop1 (Gau (None, None, None, 4 0           ada_in_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_right0_relu1 (ReLU)        (None, None, None, 4 0           unet_right0_gaussian_drop1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unet_out_AdaIN_b (Dense)        (None, 2)            770         mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_out_AdaIN_g (Dense)        (None, 2)            770         mapping_hidden_relu4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "unet_out_conv (Conv2D)          (None, None, None, 2 864         unet_right0_relu1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 1, 1, 2)      0           unet_out_AdaIN_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 1, 1, 2)      0           unet_out_AdaIN_g[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ada_in_15 (AdaIN)               (None, None, None, 2 0           unet_out_conv[0][0]              \n",
      "                                                                 reshape_30[0][0]                 \n",
      "                                                                 reshape_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "unet_out_relu (ReLU)            (None, None, None, 2 0           ada_in_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet_exit (Conv2D)              (None, None, None, 1 3           unet_out_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,887,495\n",
      "Trainable params: 5,885,383\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_style.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import model:\n",
      "/glade/work/ksha/data/Keras/BACKUP/STRANS_G_TMEAN_jja.hdf\n"
     ]
    }
   ],
   "source": [
    "model_import_dir = temp_dir\n",
    "W = tu.dummy_loader(model_import_dir+'STRANS_G_TMEAN_jja.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_style.set_weights(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x2b9b2a3b4fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a3b4f10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a363810>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a3dc850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a3dcdd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a3f5110>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a46af50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a46a510>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a47ce50>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a511b10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a577d50>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x2b9b2a362c90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a515dd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a362d50>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a58de50>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a36c850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a5aca90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a36c8d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a5b4410>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b19224dd0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a62ca90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a36c450>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a644190>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9a6fcfb050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a652250>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a35e3d0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a6ca690>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a371150>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a6cae50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a371690>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2b9b2a6dc610>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a39db50>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a765e50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a776bd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2a80fa50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a765350>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b2a8085d0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b2a808f50>,\n",
       " <model_utils.AdaIN at 0x2b9b2a83dad0>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b2a82b790>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2a82bf10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2DTranspose at 0x2b9b2a850610>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9a6fcfb090>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b23064690>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2a8b64d0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b23caf190>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b23067490>,\n",
       " <model_utils.AdaIN at 0x2b9b2305f4d0>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b230599d0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b23059450>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x2b9b230467d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b230434d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b2303d8d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b23485dd0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b23042410>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b1b1faed0>,\n",
       " <model_utils.AdaIN at 0x2b9b23033450>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b23038250>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b23025e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2DTranspose at 0x2b9b234550d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b22ffdc50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b19224090>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b1bbf0250>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b22ffda50>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b22ffb690>,\n",
       " <model_utils.AdaIN at 0x2b9b23070f50>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b23ca1710>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b232ce050>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x2b9b22ff6d50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b23672b10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b23672b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2349cc10>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b23672390>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b22fedb50>,\n",
       " <model_utils.AdaIN at 0x2b9b23c86cd0>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b22fe7750>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b23419050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2DTranspose at 0x2b9b23672c50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b1b7c00d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b1b431c90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b22fe0fd0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b1b78c150>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b1a547a10>,\n",
       " <model_utils.AdaIN at 0x2b9b1a710350>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b1976ca90>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b1baa7b10>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x2b9b1964bb90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b1b79ff90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b1b5176d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b196d6a10>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b1b5a9fd0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b1b622190>,\n",
       " <model_utils.AdaIN at 0x2b9b1b0f8950>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianDropout at 0x2b9b1a7ee690>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b1a205210>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b195d6f50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2b9b193a8d90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b1a6cb450>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b19387290>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x2b9b23ed0c50>,\n",
       " <model_utils.AdaIN at 0x2b9b19487c90>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x2b9b2aa29e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2b9b2aa29ed0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_style.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling D\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "# model_name = 'NEO_D_TMEAN_{}_pretrain'.format(sea) # GAN_D_{}_{}\n",
    "# model_path = temp_dir+model_name+'.hdf'\n",
    "\n",
    "# print('Import model: {}'.format(model_name))\n",
    "# backbone = keras.models.load_model(model_path)\n",
    "# W = backbone.get_weights()\n",
    "\n",
    "input_size = (None, None, N_input+1)\n",
    "D = mu.vgg_descriminator(N, input_size)\n",
    "\n",
    "opt_D = keras.optimizers.Adam(lr=l[1])\n",
    "print('Compiling D')\n",
    "D.compile(loss=keras.losses.mean_squared_error, optimizer=opt_D)\n",
    "#D.set_weights(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling GAN\n"
     ]
    }
   ],
   "source": [
    "D.trainable = False\n",
    "for layer in D.layers:\n",
    "    layer.trainable = False\n",
    "#\n",
    "GAN_IN1 = keras.layers.Input(shape=[latent_size])\n",
    "GAN_IN2 = keras.layers.Input(shape=[latent_size])\n",
    "GAN_IN3 = keras.layers.Input((None, None, N_input))\n",
    "\n",
    "G_OUT = G_style([GAN_IN1, GAN_IN2, GAN_IN3])\n",
    "D_IN = keras.layers.Concatenate()([G_OUT, GAN_IN3])\n",
    "D_OUT = D(D_IN)\n",
    "GAN = keras.models.Model([GAN_IN1, GAN_IN2, GAN_IN3], [G_OUT, D_OUT])\n",
    "# optimizer\n",
    "opt_GAN = keras.optimizers.Adam(lr=l[0])\n",
    "print('Compiling GAN')\n",
    "# content_loss + 1e-3 * adversarial_loss\n",
    "GAN.compile(loss=[keras.losses.mean_squared_error, keras.losses.binary_crossentropy], \n",
    "            loss_weights=[1.0, lmd],\n",
    "            optimizer=opt_GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Training settings ---------- #\n",
    "# Macros\n",
    "input_flag = [False, False, False, False, False, True] # LR T2, HR elev, LR elev\n",
    "output_flag = [False, False, False, False, True, False] # HR T2\n",
    "inout_flag = [False, False, False, False, True, True]\n",
    "labels = ['batch', 'batch'] # input and output labels\n",
    "\n",
    "# Filepath\n",
    "file_path = BATCH_dir\n",
    "trainfiles = glob(file_path+'TMEAN_BATCH_*_TORI_*{}*.npy'.format(sea)) # e.g., TMAX_BATCH_128_VORIAUG_mam30.npy\n",
    "validfiles = glob(file_path+'TMEAN_BATCH_*_VORI_*{}*.npy'.format(sea))\n",
    "# shuffle filenames\n",
    "shuffle(trainfiles)\n",
    "shuffle(validfiles)\n",
    "#\n",
    "L_train = len(trainfiles)\n",
    "gen_valid = tu.grid_grid_gen_noise(validfiles, labels, input_flag, output_flag, latent_size, sampling=2)\n",
    "\n",
    "# model names\n",
    "G_name = '{}_G_TMEAN_{}'.format(key, sea)\n",
    "D_name = '{}_D_TMEAN_{}'.format(key, sea)\n",
    "G_path = temp_dir+G_name+'.hdf'\n",
    "D_path = temp_dir+D_name+'.hdf'\n",
    "hist_path = temp_dir+'{}_LOSS_TMEAN_{}.npy'.format(key, sea)\n",
    "\n",
    "# loss backup\n",
    "GAN_LOSS = np.zeros([int(epochs*L_train), 3])*np.nan\n",
    "D_LOSS = np.zeros([int(epochs*L_train)])*np.nan\n",
    "V_LOSS = np.zeros([epochs])*np.nan           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "\t0 step loss = [1.7764993, 1.7761368, 0.3625432]\n",
      "\t50 step loss = [1.0109146, 1.0097383, 1.1762408]\n",
      "\t100 step loss = [0.96827346, 0.96679986, 1.4736171]\n",
      "\t150 step loss = [0.8171611, 0.81634235, 0.8187239]\n",
      "\t200 step loss = [0.7714116, 0.7705031, 0.9084961]\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.6775\n",
      "Validation loss improved from 999 to 0.6774541662063127\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "WARNING:tensorflow:From /glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 283.16722774505615 seconds ---\n",
      "epoch = 1\n",
      "\t0 step loss = [0.6868811, 0.6861192, 0.76195407]\n",
      "\t50 step loss = [0.6269495, 0.62614983, 0.7996398]\n",
      "\t100 step loss = [0.66694015, 0.66605514, 0.88498425]\n",
      "\t150 step loss = [0.5704123, 0.5695648, 0.84744805]\n",
      "\t200 step loss = [0.5929875, 0.5919948, 0.99266315]\n",
      "81/81 [==============================] - 18s 220ms/step - loss: 0.5259\n",
      "Validation loss improved from 0.6774541662063127 to 0.525872974851985\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 266.7740948200226 seconds ---\n",
      "epoch = 2\n",
      "\t0 step loss = [0.54189587, 0.5408821, 1.0137609]\n",
      "\t50 step loss = [0.55110025, 0.5500064, 1.0938389]\n",
      "\t100 step loss = [0.42066774, 0.41956806, 1.0996661]\n",
      "\t150 step loss = [0.4382112, 0.43715614, 1.0550611]\n",
      "\t200 step loss = [0.29642546, 0.29535288, 1.072571]\n",
      "81/81 [==============================] - 18s 218ms/step - loss: 0.3181\n",
      "Validation loss improved from 0.525872974851985 to 0.3181261913276013\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 264.13416051864624 seconds ---\n",
      "epoch = 3\n",
      "\t0 step loss = [0.33081675, 0.3298598, 0.9569631]\n",
      "\t50 step loss = [0.27528736, 0.274288, 0.9993484]\n",
      "\t100 step loss = [0.2319164, 0.23092054, 0.9958586]\n",
      "\t150 step loss = [0.29188228, 0.2909476, 0.93468964]\n",
      "\t200 step loss = [0.33491436, 0.33392718, 0.9871681]\n",
      "81/81 [==============================] - 19s 231ms/step - loss: 0.2551\n",
      "Validation loss improved from 0.3181261913276013 to 0.2551135954297619\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 268.27219247817993 seconds ---\n",
      "epoch = 4\n",
      "\t0 step loss = [0.29489464, 0.29394287, 0.9517688]\n",
      "\t50 step loss = [0.22529665, 0.22426347, 1.0331749]\n",
      "\t100 step loss = [0.26030615, 0.25934884, 0.95732236]\n",
      "\t150 step loss = [0.25415805, 0.25319836, 0.95970666]\n",
      "\t200 step loss = [0.28624687, 0.28532514, 0.9217194]\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.2336\n",
      "Validation loss improved from 0.2551135954297619 to 0.23356310802477379\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 276.6571762561798 seconds ---\n",
      "epoch = 5\n",
      "\t0 step loss = [0.23547591, 0.23453307, 0.94284713]\n",
      "\t50 step loss = [0.20196047, 0.20105928, 0.90118563]\n",
      "\t100 step loss = [0.19026726, 0.189334, 0.93326104]\n",
      "\t150 step loss = [0.19332123, 0.19241749, 0.9037476]\n",
      "\t200 step loss = [0.19829741, 0.19738746, 0.90994745]\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.2210\n",
      "Validation loss improved from 0.23356310802477379 to 0.22100923808268558\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 271.2692697048187 seconds ---\n",
      "epoch = 6\n",
      "\t0 step loss = [0.26163208, 0.2607012, 0.9308873]\n",
      "\t50 step loss = [0.26180837, 0.2609074, 0.9009656]\n",
      "\t100 step loss = [0.17075153, 0.16985096, 0.90056986]\n",
      "\t150 step loss = [0.26002356, 0.2591294, 0.8941471]\n",
      "\t200 step loss = [0.20405138, 0.20318472, 0.8666551]\n",
      "81/81 [==============================] - 17s 213ms/step - loss: 0.2079\n",
      "Validation loss improved from 0.22100923808268558 to 0.20792268658125843\n",
      "tol: 0\n",
      "save to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf\n",
      "\t/glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_G_TMEAN_jja.hdf/assets\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/data/Keras/BACKUP/TEST_D_TMEAN_jja.hdf/assets\n",
      "--- 264.85580706596375 seconds ---\n",
      "epoch = 7\n",
      "\t0 step loss = [0.1807449, 0.17978492, 0.95997673]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d42a5b04e590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0md_in_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0md_in_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minout_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_in_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_good\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_in_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     output, mean, variance = tf_utils.smart_cond(\n\u001b[0;32m--> 517\u001b[0;31m         training, _fused_batch_norm_training, _fused_batch_norm_inference)\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bessels_correction_test_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;31m# Remove Bessel's correction to be consistent with non-fused batch norm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    501\u001b[0m           \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m           data_format=self._data_format)\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   1482\u001b[0m   \"\"\"\n\u001b[1;32m   1483\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m   \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m   \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"offset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     result = gen_resource_variable_ops.read_variable_op(self._handle,\n\u001b[1;32m    608\u001b[0m                                                         self._dtype)\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m   \u001b[0;34m\"\"\"Records that `variable` was accessed for the tape and FuncGraph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"watch_variable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5875\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m   \"\"\"\n\u001b[0;32m-> 5877\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5456\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5457\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5459\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tol = 0\n",
    "batch_size = 200\n",
    "train_size = 100\n",
    "record = 999\n",
    "for i in range(epochs):\n",
    "    print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # shuffling at epoch begin\n",
    "    shuffle(trainfiles)\n",
    "    \n",
    "    # loop over batches\n",
    "    for j, name in enumerate(trainfiles):        \n",
    "        \n",
    "        # ----- import batch data subset ----- #\n",
    "        inds = du.shuffle_ind(batch_size)[:train_size]\n",
    "        temp_batch = np.load(name, allow_pickle=True)[()]\n",
    "        X = temp_batch['batch'][inds, ...]\n",
    "        # ------------------------------------ #\n",
    "        \n",
    "        # ----- D training ----- #\n",
    "        # Latent space sampling\n",
    "        Wf1 = np.random.normal(0.0, 1.0, size = [train_size, latent_size])\n",
    "        Wf2 = np.random.normal(0.0, 1.0, size = [train_size, latent_size])\n",
    "        # soft labels\n",
    "        dummy_bad = np.ones(train_size)*0.1 + np.random.uniform(-0.02, 0.02, train_size)\n",
    "        dummy_good = np.ones(train_size)*0.9 + np.random.uniform(-0.02, 0.02, train_size)\n",
    "        # get G_output (channel last)\n",
    "        g_in = [Wf1, Wf2, X[..., input_flag]]\n",
    "        g_out = G_style.predict(g_in) # <-- np.array\n",
    "        # train on batch\n",
    "        d_in_fake = np.concatenate((g_out, X[..., input_flag]), axis=-1)\n",
    "        d_in_true = X[..., inout_flag]\n",
    "        d_loss1 = D.train_on_batch(d_in_true, dummy_good)\n",
    "        d_loss2 = D.train_on_batch(d_in_fake, dummy_bad)\n",
    "        d_loss = d_loss1 + d_loss2\n",
    "        # ----------------------- #\n",
    "        \n",
    "        # ----- G training ----- #\n",
    "        # Latent space sampling\n",
    "        Wf1 = np.random.normal(0.0, 1.0, size = [train_size, latent_size])\n",
    "        Wf2 = np.random.normal(0.0, 1.0, size = [train_size, latent_size])\n",
    "        # soft labels\n",
    "        dummy_good = np.ones(train_size)*0.9 + np.random.uniform(-0.02, 0.02, train_size)\n",
    "        # train on batch\n",
    "        gan_in = [Wf1, Wf2, X[..., input_flag]]\n",
    "        gan_target = [X[..., output_flag], dummy_good]\n",
    "        gan_loss = GAN.train_on_batch(gan_in, gan_target)\n",
    "        # ---------------------- #\n",
    "        \n",
    "        # ----- Backup training loss ----- #\n",
    "        D_LOSS[i*L_train+j] = d_loss\n",
    "        GAN_LOSS[i*L_train+j, :] = gan_loss\n",
    "        # -------------------------------- #\n",
    "        if j%50 == 0:\n",
    "            print('\\t{} step loss = {}'.format(j, gan_loss))\n",
    "    # on epoch-end\n",
    "    record_temp = G_style.evaluate_generator(gen_valid, verbose=1)\n",
    "\n",
    "    # Backup validation loss\n",
    "    V_LOSS[i] = record_temp\n",
    "    # Overwrite loss info\n",
    "    LOSS = {'GAN_LOSS':GAN_LOSS, 'D_LOSS':D_LOSS, 'V_LOSS':V_LOSS}\n",
    "    np.save(hist_path, LOSS)\n",
    "\n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}\\n\\t{}'.format(G_path, D_path))\n",
    "        G_style.save(G_path)\n",
    "        D.save(D_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            print('Pass to the next epoch')\n",
    "            continue;\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
